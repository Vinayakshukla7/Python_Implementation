{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is urllib ?\n",
    "Urllib module is the URL handling module for python. It is used to fetch URLs (Uniform Resource Locators). It uses the urlopen function and is able to fetch URLs using a variety of different protocols. Building ,loading and parsing the url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Using\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import urllib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Urllib is a package that collects several modules for working with URLs, such as:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "urllib.request for opening and reading URLs.\n",
    "urllib.parse for parsing URLs \n",
    "urllib.error for the exceptions raised by urllib.request\n",
    "urllib.robotparser for parsing robot.txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urllib.request\n",
    "This module helps to define functions and classes to open URLs (mostly HTTP). One of the most simple ways to open such URLs is : urllib.request.urlopen(url)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "request_url = urllib.request.urlopen('https://www.google.com')\n",
    "print(request_url.read()) #it will print source code of google page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urllib.parse\n",
    "This module helps to define functions to manipulate URLs and their components parts, to build or break them. It usually focuses on splitting a URL into small components; or joining different URL components into URL string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='https', netloc='www.google.com', path='/python', params='', query='', fragment='')\n",
      "\n",
      "\n",
      "https://www.google.com/python\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import *\n",
    "parse_url = urlparse('https://www.google.com/python')\n",
    "print(parse_url)\n",
    "print(\"\\n\")\n",
    "unparse_url = urlunparse(parse_url)\n",
    "print(unparse_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different other functions of urllib.parse are :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "urllib.parse.urlparse -----Separates different components of URL\n",
    "urllib.parse.urlunparse\t-----Join different components of URL\n",
    "urllib.parse.urlsplit\t-----It is similar to urlparse() but doesn’t split the params\n",
    "urllib.parse.urlunsplit\t------Combines the tuple element returned by urlsplit() to form URL\n",
    "urllib.parse.urldeflag\t------If URL contains fragment, then it returns a URL removing the fragment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urllib.error\n",
    "This module defines the classes for exception raised by urllib.request. Whenever there is an error in fetching a URL, this module helps in raising exceptions. The following are the exceptions raised :\n",
    "\n",
    "URLError – It is raised for the errors in URLs, or errors while fetching the URL due to connectivity, and has a ‘reason’ property that tells a user the reason of error.\n",
    "\n",
    "HTTPError – It is raised for the exotic HTTP errors, such as the authentication request errors. It is a subclass or URLError. Typical errors include ‘404’ (page not found), ‘403’ (request forbidden),\n",
    "and ‘401’ (authentication required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urlopen error [Errno 11001] getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "  \n",
    "# trying to read the URL but with no internet connectivity\n",
    "try:\n",
    "    x = urllib.request.urlopen('https://www.google.com')\n",
    "    print(x.read())\n",
    "  \n",
    "# Catching the exception generated     \n",
    "except Exception as e :\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urllib.robotparser \n",
    "This module provides a single class, RobotFileParser, which answers questions about whether or not a particular user agent can fetch a URL on the Web site that published the robots.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
