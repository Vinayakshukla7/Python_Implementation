{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Scrapy ?\n",
    "Scrapy is a fast, open-source web crawling framework written in Python,\n",
    "Used for extracting the data you need from websites.In a fast, simple, yet extensible way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why use scrapy ?\n",
    "It is easier to build and scale large crawling projects.<br>\n",
    "It has a built-in mechanism called Selectors, for extracting the data from websites.<br>\n",
    "It handles the requests asynchronously and it is fast.<br>\n",
    "Scrapy generates feed exports in formats such as JSON, CSV, and XML.<br>\n",
    "Scrapy has built-in support for selecting and extracting data from sources either by XPath or CSS expressions.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a project"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scrapy startproject first_scrapy                                          #first_scrapy is our project name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will create a first_scrapy directory with the following contents:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "first_scrapy/\n",
    "    scrapy.cfg            # deploy configuration file\n",
    "\n",
    "    first_scrapy/             # project's Python module, you'll import your code from here\n",
    "        __init__.py\n",
    "\n",
    "        items.py          # project items definition file\n",
    "\n",
    "        middlewares.py    # project middlewares file\n",
    "\n",
    "        pipelines.py      # project pipelines file\n",
    "\n",
    "        settings.py       # project settings file\n",
    "\n",
    "        spiders/          # a directory where you'll later put your spiders\n",
    "            __init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape product's  name,price,link from website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To create a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy startproject whiskyscrapper                              #whiskyscrapper is name of project                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Scrapy shell\n",
    "when we are using scrapy shell everything is going to be save in response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd whiskyscrapper  #get to directory\n",
    " \n",
    "scrapy shell      #enable shell\n",
    "\n",
    "fetch('https://www.whiskyshop.com/scotch-whisky')          #fetch method to get the link which returns reponse object\n",
    "\n",
    "#response shows get<200> then good to go else check url once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection of website\n",
    "Will help to get the elements from which we will scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.css('div.product-item-info')     #selector used to select specify tag\n",
    "\n",
    "response.css('div.product-item-info').get()       #get() used to get that content ,givesonly first found element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product=response.css('div.product-item-info')\n",
    "len(product)                               #100 i.e... no of producct per page         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product.css('a.product-item-link::text').getall()     #will give name of all 100 products\n",
    "\n",
    "product.css('span.price::text').getall()           #will give prices of all 100 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product.css('a.product-item-link').attrib['href']         #links of product items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Spider\n",
    "Spiders are classes that you define and that Scrapy uses to scrape information from a website (or a group of websites). They must subclass Spider and define the initial requests to make, optionally how to follow links in the pages, and how to parse the downloaded page content to extract data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapy genspider whiskyspider www.whiskyshop.com/scotch-whisky         #scrapy spider genspider class_name link_given ,will create spider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes made in Spider \n",
    "i.e.. in whiskyspider.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class WhiskyspiderSpider(scrapy.Spider):\n",
    "    name = 'whisky'\n",
    "    allowed_domains = ['www.whiskyshop.com/scotch-whisky']\n",
    "    start_urls = ['http://www.whiskyshop.com/scotch-whisky/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        for product in response.css('div.product-item-info'):\n",
    "            try:    \n",
    "                yield{\n",
    "                    'name': product.css('a.product-item-link::text').get(),\n",
    "                    'price': product.css('span.price::text').get().replace('Â£',''),\n",
    "                    'link':  product.css('a.product-item-link').attrib['href'] ,\n",
    "                }\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Crawl the Spider\n",
    "Basically it means to run the project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider crawl whisky                                                          #spider crawl spider_name  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert output into .json format\n",
    "scrapy crawl whisky -O whisky.json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
